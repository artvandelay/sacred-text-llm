# Sacred Texts LLM - Phase 2 Deployment Configuration
# Hybrid setup: Local ChromaDB + Cloud OpenRouter LLM
# Copy this file to .env and configure your settings

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# Phase 2: Cloud OpenRouter for better chat models
LLM_PROVIDER=openrouter

# =============================================================================
# OLLAMA SETTINGS (Local - Fallback)
# =============================================================================

# Local Ollama model (fallback if OpenRouter fails)
OLLAMA_CHAT_MODEL=qwen3:30b-a3b
OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# OPENROUTER SETTINGS (Cloud - Primary)
# =============================================================================

# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your-api-key-here

# OpenRouter model (Claude 3.5 Sonnet recommended for best quality)
OPENROUTER_CHAT_MODEL=anthropic/claude-3.5-sonnet

# Alternative models you can try:
# OPENROUTER_CHAT_MODEL=anthropic/claude-3-opus-20240229  # Best quality, higher cost
# OPENROUTER_CHAT_MODEL=openai/gpt-4o-mini                # Good balance
# OPENROUTER_CHAT_MODEL=meta-llama/llama-3.1-70b-instruct # Open source option

# OpenRouter API URL (usually don't change this)
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# =============================================================================
# VECTOR DATABASE SETTINGS
# =============================================================================

# Embedding model for vector search (still local)
EMBEDDING_MODEL=nomic-embed-text

# Local ChromaDB storage directory (keeps data local)
VECTOR_STORE_DIR=vector_store/chroma

# Collection name for sacred texts
COLLECTION_NAME=sacred_texts

# =============================================================================
# DEPLOYMENT SETTINGS
# =============================================================================

# Web server configuration
WEB_PORT=8001
WEB_HOST=0.0.0.0

# ngrok configuration
NGROK_REGION=us

# =============================================================================
# AGENT BEHAVIOR SETTINGS
# =============================================================================

# Research depth and iteration limits
MAX_RESEARCH_ITERATIONS=8
MAX_QUERIES_PER_ITERATION=20
MAX_PARALLEL_QUERIES=10

# Confidence and evidence thresholds
CONFIDENCE_THRESHOLD=0.75
MAX_TOTAL_EVIDENCE_CHUNKS=15

# UI and progress display
SHOW_AGENT_PROGRESS=true
SHOW_DETAILED_PROGRESS=true

# =============================================================================
# PHASE 2 SPECIFIC SETTINGS
# =============================================================================

# Rate limiting for OpenRouter API
OPENROUTER_RATE_LIMIT=10  # requests per minute

# Fallback to Ollama if OpenRouter fails
ENABLE_OLLAMA_FALLBACK=true

# Cost monitoring (optional)
ENABLE_COST_MONITORING=true
